
learner         :       MMKD
optim           :       SGD
learning_rate   :       0.01
momentum        :       0.9
weight_decay    :       0.0001
dataset         :       tiny
n_tasks         :       100
mem_size        :       10000
mem_batch_size  :       64
batch_size      :       10
nf              :       64
tf_type         :       full
training_type   :       inc
kd_lambda       :       8
n_teacher       :       1
alpha_min       :       0.01
alpha_max       :       0.01
